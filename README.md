# Pipeline ETL - Engenharia e AnÃ¡lise de Dados musicais

## ğŸ“Š Sobre o Projeto
Projeto de Engenharia de Dados que consiste em criar um pipeline de ETL, desenvolvido para coletar e processar dados histÃ³ricos das paradas musicais mundiais desde 1950. O projeto realiza web scraping do site The World's Music Charts, processando informaÃ§Ãµes de mais de 500 mil entradas de charts musicais de 22 paÃ­ses diferentes.


![diagrama2](https://github.com/user-attachments/assets/07e6eefd-d6ca-46f7-9e2c-a1bedf255cf7)



## ğŸ—ï¸ Arquitetura

O projeto estÃ¡ estruturado em duas camadas principais:

### Layer Bronze
- Web scraping do The World's Music Charts
- Armazenamento dos dados brutos em formato Parquet no MinIO
- PersistÃªncia em tabela 'albums_bronze' no MariaDB

### Layer Silver
- Processamento dos dados da camada Bronze
- NormalizaÃ§Ã£o da estrutura (separaÃ§Ã£o das entradas nas paradas em registros individuais)
- Armazenamento em formato Parquet no MinIO
- PersistÃªncia na tabela 'albums_silver' no MariaDB

### Layer Gold
- CriaÃ§Ã£o das tabelas dimensÃ£o;
- CriaÃ§Ã£o da tabela fato relacionada Ã s entradas nas paradas de sucesso;
- Enriquecimento com um novo scraping para criaÃ§Ã£o da tabela dimensÃ£o com informaÃ§Ãµes sobre cada parada;
  
## ğŸ› ï¸ Tecnologias Utilizadas

- **Docker**: ContainerizaÃ§Ã£o do ambiente
- **Apache Airflow**: OrquestraÃ§Ã£o das tasks
- **MinIO**: Armazenamento de arquivos
- **MariaDB**: Banco de dados relacional
- **Python**: Linguagem principal para ETL
- **DBeaver**: Interface para gestÃ£o do banco de dados
- **Apache Superset**: Ferramenta de data viz utilizada para gerar dashboards a partir da camada gold

## ğŸ“ˆ Dataset

O projeto utiliza dados do The World's Music Charts, que inclui:
- 529.468 entradas individuais em paradas musicais
- 238 charts diferentes de 22 paÃ­ses
- 154.916 mÃºsicas e 89.258 Ã¡lbuns
- Dados de mais de 40.000 artistas

## ğŸš€ Como Executar

1. Clone o repositÃ³rio
```bash
git clone https://github.com/devleomarinho/music_charts_etl.git

```

2. Configure o ambiente Docker
```bash
docker-compose up -d
```

3. Acesse a interface do Airflow
```bash
http://localhost:8080
```

4. Acesse a interface do MinIO:
```bash
http://localhost:9001/
```

5. Acesse a interface do Apache Superset:
```bash
http://localhost:8088/
```

## Melhorias futuras

Este projeto estÃ¡ funcionando, todas as imagens estÃ£o sendo criadas corretamente no docker compose, o script de webscraping estÃ¡ funcionando e as tasks do airflow estÃ£o rodando, as camadas bronze, silver e gold estÃ£o sendo criadas tambÃ©m. EstÃ¡ faltando apenas a criaÃ§Ã£o dos dashboards no Apache Superset, entÃ£o fique Ã  vontade para criar as suas prÃ³prias anÃ¡lises!
